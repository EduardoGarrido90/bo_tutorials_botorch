{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# BOTorch tutorial. Fairness MOBO.\n",
        "Here we illustrate how to tune two machine learning hyper-parameters using BOTorch. In this notebook we will compare BO's performance with respect to RS."
      ],
      "metadata": {
        "id": "Ut_7qUec_fPS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "First we install BOTorch"
      ],
      "metadata": {
        "id": "lUHXZaZ-EBaH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install botorch"
      ],
      "metadata": {
        "id": "DRylSzQ1EC0X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import libraries. We will just tune the alpha regularization term of a MLPClassifier, the number of neurons in the hidden layer and the momentum value on a synthetic classification problem."
      ],
      "metadata": {
        "id": "aLB1XvRk_cp0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H_k6vXoy_Y4p"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "import plotly\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "seed=1\n",
        "np.random.seed(seed)\n",
        "torch.manual_seed(seed)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Objective function: Estimation of the generalization error measured by the lower confidence bound of the accuracy loss function of a multilayer perceptron whose weights are estimated via a k-fold cross validation on a synthetic dataset of 20 variables $\\mathbf{X}$ to perform binary classification of the dummy variable $y$. We do not need to shuffle the dataset as it is synthetic, but watch out of that for real problems."
      ],
      "metadata": {
        "id": "sO5iEVhA_n8i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X, y = make_classification(n_samples=2000, random_state=1)"
      ],
      "metadata": {
        "id": "6VmkhXB4-VTY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We have a low fidelity of the real performance brought by this classifier here as I limit the number of epochs of the MLP to 150 for didactic purposes. Also, the variance of the classifier can be improved by setting a higher number of folds, but I also set it to 3 for didactic purposes. We set the synthetic problem to be common for all the experiments. Our two objectives will be inversely correlated, one minimizes the accuracy and the other the true positive rate, usually used for fairness to protect the weak class value (gender, race, disability, religion, etc...). "
      ],
      "metadata": {
        "id": "9GS_cR4tD9UH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.model_selection import cross_validate\n",
        "\n",
        "def confusion_matrix_scorer(clf, X, y):\n",
        "      y_pred = clf.predict(X)\n",
        "      cm = confusion_matrix(y, y_pred)\n",
        "      return {'tpr': (cm[1, 1])/(cm[0,0] + cm[0,1] + cm[1,0] + cm[1,1]), 'accuracy': (cm[0,0] + cm[1,1])/(cm[0,0] + cm[0,1] + cm[1,0] + cm[1,1])}\n",
        "\n",
        "def target_function(hyperparameter_sample, seed=1, fidelity=\"low\"):\n",
        "  #For more clarity, I declare a variable for each hyper-parameter, although it is a begginer move. \n",
        "  if fidelity == \"low\":\n",
        "    max_epochs = 200\n",
        "    folds = 3\n",
        "  else: \n",
        "    max_epochs = 500\n",
        "    folds = 10\n",
        "  alpha_regularizer = float(hyperparameter_sample[0])\n",
        "  momentum_value = float(hyperparameter_sample[1])\n",
        "  hidden_layer_size_value = int(hyperparameter_sample[2])\n",
        "  X, y = make_classification(n_samples=1000, random_state=1)\n",
        "  clf = MLPClassifier(random_state=seed, max_iter=max_epochs, alpha=alpha_regularizer, momentum=momentum_value, hidden_layer_sizes=(hidden_layer_size_value))\n",
        "  scores = cross_validate(clf, X, y, scoring=confusion_matrix_scorer, cv=folds)\n",
        "  obj_function_1 = scores['test_accuracy']\n",
        "  obj_function_2 = scores['test_tpr']\n",
        "  obj_function_1 = obj_function_1.mean() - obj_function_1.std()\n",
        "  obj_function_2 = obj_function_2.mean() - obj_function_2.std()\n",
        "  result = []\n",
        "  result.append(obj_function_1)\n",
        "  result.append(obj_function_2)\n",
        "  print(\"Estimation of the accuracy and TPR of the MLP on the synthetic dataset done\")\n",
        "  return result"
      ],
      "metadata": {
        "id": "pBQXY7oZ_o3S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Print the accuracy function of the alpha hyper-parameter, that we want to maximize. Here we set the resolution to 100 for didactic purposes. As the 3-fold CV estimates three models to estimate the value of the accuracy parameter that represents the generalization error, we are really training 300 models here. So this may be computationally costly. The other hyper-parameters are set by default, to see the whole function over the input space we would need a 3D visualization. We could also consider as alternative objectives fit_time y score_time to obtain a compromise between faster models or more accurate models. First element is accuracy, second is TPR. We can see how they are inversely correlated."
      ],
      "metadata": {
        "id": "F6FwE1eYABoy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import plotly.graph_objects as go\n",
        "\n",
        "lower_bound = 0.000001\n",
        "upper_bound = 0.1\n",
        "resolution = 10\n",
        "n_objectives = 2\n",
        "#resolution = 100\n",
        "x = np.linspace(lower_bound, upper_bound, resolution)\n",
        "x_new = x.reshape((resolution,-1))\n",
        "z = np.array([target_function(np.array([alpha, 0.9, 20])) for alpha in x]).reshape((resolution, n_objectives))\n",
        "accuracy = z[:,0]\n",
        "tpr = z[:,1]\n",
        "data1 = go.Scatter(x=x, y=accuracy, line_color=\"#FE73FF\", name=\"Accuracy\")\n",
        "data2 = go.Scatter(x=x, y=tpr, line_color=\"#FE73FF\", name=\"TPR\")\n",
        "\n",
        "fig1 = go.Figure(data=data1)\n",
        "fig2 = go.Figure(data=data2)\n",
        "fig1.update_layout(title=\"Accuracy, estimated by 3-fold-CV\", xaxis_title=\"Alpha regularizer value\", yaxis_title=\"Accuracy\")\n",
        "fig1.show()\n",
        "fig2.update_layout(title=\"TPR estimated by 3-fold-CV\", xaxis_title=\"Alpha regularizer value\", yaxis_title=\"TPR\")\n",
        "fig2.show()"
      ],
      "metadata": {
        "id": "ZlqngMKbAEA6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We now set the bounds for the optimization. First one is the range of the alpha hyper-parameter, then the range for the momentum hyper-parameter and, lastly, the range of the number of neurons of the MLP. Our input space is hence a cube contained in $\\mathbb{R}^3$."
      ],
      "metadata": {
        "id": "Q5pPnMeXAJXt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bounds = np.array([[0.000001, 0.8, 10],[0.1, 0.999, 300]])"
      ],
      "metadata": {
        "id": "W_qml9fAAMFf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Generate some data. Example of 1000 random points from the input space, normalized into the range. We can see that their values lie in the range."
      ],
      "metadata": {
        "id": "H3VlN1QSBIJs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_x = torch.rand(1000, len(bounds[0])) * (bounds[1] - bounds[0]) + bounds[0]\n",
        "print(torch.min(train_x, axis=0))\n",
        "print(torch.max(train_x, axis=0))"
      ],
      "metadata": {
        "id": "-FzuqL7TBJSy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can observe a random sample of the hyper-parameter uniform distribution. "
      ],
      "metadata": {
        "id": "X3kPMk5lByR3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_x[0]"
      ],
      "metadata": {
        "id": "4JmhWlAlBvKj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Then we compute the latent function $f(\\mathbf{x})$. The true evaluation would be contaminated. $\\mathbf{y} = f(\\mathbf{x}) + \\epsilon \\quad s.t. \\quad \\epsilon \\approx N(0, \\sigma) \\quad f: \\mathbb{R}^3 \\to \\mathbb{R}^2$"
      ],
      "metadata": {
        "id": "FSg7ptujBZkG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "exact_obj = target_function(train_x[0], seed=seed)\n",
        "exact_obj"
      ],
      "metadata": {
        "id": "cI-7IyqPBOru"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We wrap all of the previous code into a function to be used freely"
      ],
      "metadata": {
        "id": "ibI-21seCe6U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_initial_data(n=10):\n",
        "  train_x = torch.rand(n, len(bounds[0])) * (bounds[1] - bounds[0]) + bounds[0]\n",
        "  exact_obj = torch.tensor([target_function(sample) for sample in train_x])\n",
        "  best_observed_value = exact_obj.max().item()\n",
        "  return train_x, exact_obj, best_observed_value"
      ],
      "metadata": {
        "id": "QX6Y4KY4ChtU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generate_initial_data(3)"
      ],
      "metadata": {
        "id": "joClmvvSCz5C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let us now invoke this function to start the BO iteration."
      ],
      "metadata": {
        "id": "q8merVh3DEZM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "init_x, init_y, best_init_y = generate_initial_data(3)"
      ],
      "metadata": {
        "id": "mqXQD_GxDGxS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We now declare a function that give us a suggestion with respect to the GP fitted to previous points."
      ],
      "metadata": {
        "id": "NNgRjAMYEc75"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "init_y.shape"
      ],
      "metadata": {
        "id": "oC-HT5zFo27z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from botorch.optim import optimize_acqf\n",
        "from botorch.utils.transforms import normalize, unnormalize\n",
        "from botorch.models.transforms.outcome import Standardize\n",
        "from botorch.models import SingleTaskGP\n",
        "from botorch.models.model_list_gp_regression import ModelListGP\n",
        "from gpytorch.mlls.sum_marginal_log_likelihood import SumMarginalLogLikelihood\n",
        "from botorch.utils.multi_objective.box_decompositions.non_dominated import FastNondominatedPartitioning\n",
        "from botorch.acquisition.multi_objective.monte_carlo import qExpectedHypervolumeImprovement\n",
        "from botorch import fit_gpytorch_model\n",
        "from botorch.sampling.normal import SobolQMCNormalSampler\n",
        "from botorch.utils.multi_objective.box_decompositions.dominated import DominatedPartitioning\n",
        "\n",
        "def optimize_qehvi_and_get_observation(model, train_x, train_obj, sampler, bounds, reference_point, normalized_bounds):\n",
        "    \"\"\"Optimizes the qEHVI acquisition function, and returns a new candidate and observation.\"\"\"\n",
        "    # partition non-dominated space into disjoint rectangles\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        pred = model.posterior(normalize(train_x, bounds)).mean\n",
        "    partitioning = FastNondominatedPartitioning(\n",
        "        ref_point=reference_point, \n",
        "        Y=pred,\n",
        "    )\n",
        "    acq_func = qExpectedHypervolumeImprovement(\n",
        "        model=model,\n",
        "        ref_point=reference_point,\n",
        "        partitioning=partitioning,\n",
        "        sampler=sampler,\n",
        "    )\n",
        "    \n",
        "    # optimize\n",
        "    candidates, _ = optimize_acqf(\n",
        "        acq_function=acq_func,\n",
        "        bounds=normalized_bounds,\n",
        "        q=1,\n",
        "        num_restarts=200,\n",
        "        raw_samples=512,  # used for intialization heuristic\n",
        "        options={\"batch_limit\": 5, \"maxiter\": 200},\n",
        "        sequential=True,\n",
        "    )\n",
        "    # observe new values \n",
        "    new_x =  unnormalize(candidates.detach(), bounds=bounds)\n",
        "    new_obj = target_function(new_x[0])\n",
        "    return new_x, new_obj\n",
        "    \n",
        "def get_next_points(init_x, init_y, bounds, reference_point, normalized_bounds, n_points=1):\n",
        "  train_x = normalize(init_x, bounds)\n",
        "  models = []\n",
        "  for i in range(init_y.shape[1]):\n",
        "    train_y = init_y[..., i:i+1]\n",
        "    models.append(SingleTaskGP(train_x, train_y, outcome_transform=Standardize(m=1)))\n",
        "  model = ModelListGP(*models)\n",
        "  mll = SumMarginalLogLikelihood(model.likelihood, model)\n",
        "  fit_gpytorch_model(mll)\n",
        "  qehvi_sampler = SobolQMCNormalSampler(sample_shape=torch.Size([128]))\n",
        "  \n",
        "  configuration, observation = optimize_qehvi_and_get_observation(model, init_x, init_y, qehvi_sampler, bounds, reference_point, normalized_bounds)\n",
        "\n",
        "  return configuration, observation"
      ],
      "metadata": {
        "id": "XS4zdkHyjGWX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we will compare the performance of RS vs BO. We just do, for didactic purposes, 3 iterations with different random seed of each method. In order to do it better, we will need 30 iterations of both methods and then perform a t-test of 2 means statistical hypotheses test. We save the performance in each iteration of the methods. Both methods have an initial random observation."
      ],
      "metadata": {
        "id": "M-7Zz2G1oJbd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n_experiments = 10\n",
        "n_iterations= 50\n",
        "n_methods = 2\n",
        "\n",
        "#We store the results in this tensor, we just have two methods to compare.\n",
        "experiment_results = np.zeros((n_methods, n_experiments, n_iterations))\n",
        "experiment_configurations = np.zeros((n_methods, n_experiments, n_iterations, len(bounds[0])))\n",
        "normalized_bounds = torch.tensor([np.zeros(len(bounds[0])), np.ones(len(bounds[0]))])\n",
        "bounds = np.array([[0.000001, 0.8, 10.0],[0.1, 0.999, 300.0]])\n",
        "reference_point = torch.tensor([0.7, 0.3])\n",
        "\n",
        "for i in range(n_experiments):\n",
        "  np.random.seed(i)\n",
        "  torch.manual_seed(i)\n",
        "\n",
        "  init_x, init_y, best_init_y = generate_initial_data(1)\n",
        "\n",
        "  candidates=[]\n",
        "  results=[]\n",
        "  \n",
        "  best_observed_result_bo = DominatedPartitioning(ref_point=reference_point, Y=init_y).compute_hypervolume().item()\n",
        "  best_observed_candidate_bo = init_x[0]\n",
        "\n",
        "  random_sample_hyperparameters = torch.rand(1, len(bounds[0])) * (bounds[1] - bounds[0]) + bounds[0]\n",
        "  \n",
        "  best_observed_result_rs = DominatedPartitioning(ref_point=reference_point, Y=torch.tensor([target_function(random_sample_hyperparameters[0])])).compute_hypervolume().item()\n",
        "  best_observed_candidate_rs = random_sample_hyperparameters[0]\n",
        "\n",
        "  for j in range(n_iterations):\n",
        "\n",
        "    #BO Code.\n",
        "    new_candidates, new_results = get_next_points(init_x, init_y, bounds, reference_point, normalized_bounds)\n",
        "\n",
        "    print(f\"New candidates are: {new_candidates}\")\n",
        "    init_x = torch.cat([init_x, new_candidates])\n",
        "    init_y = torch.cat([init_y, torch.tensor([new_results])])\n",
        "\n",
        "    # compute hypervolume\n",
        "    bd = DominatedPartitioning(ref_point=reference_point, Y=init_y)\n",
        "    volume = bd.compute_hypervolume().item()\n",
        "        \n",
        "    if best_observed_result_bo < volume:\n",
        "      best_observed_result_bo = volume\n",
        "      best_observed_candidate_bo = new_candidates[0]\n",
        "\n",
        "    experiment_configurations[0,i,j,:] = best_observed_candidate_bo\n",
        "    experiment_results[0,i,j] = best_observed_result_bo\n",
        "    \n",
        "    ##RS Code.\n",
        "    #I sample the hyperparameter value for random search here.\n",
        "    random_sample_hyperparameters = torch.rand(1, len(bounds[0])) * (bounds[1] - bounds[0]) + bounds[0]\n",
        "    rs_obj_fun_result = DominatedPartitioning(ref_point=reference_point, Y=torch.tensor([target_function(random_sample_hyperparameters[0])])).compute_hypervolume().item()\n",
        "    \n",
        "    if best_observed_result_rs < rs_obj_fun_result:\n",
        "      best_observed_result_rs = rs_obj_fun_result\n",
        "      best_observed_candidate_rs = random_sample_hyperparameters[0]\n",
        "    experiment_configurations[1,i,j,:] = best_observed_candidate_rs\n",
        "    experiment_results[1,i,j] = best_observed_result_rs\n",
        "    print(\"Current best BO candidate: \" + str(best_observed_candidate_bo))\n",
        "    print(\"Current best RS candidate: \" + str(best_observed_candidate_rs))\n",
        "    print(\"Current best BO hypervolume: \" + str(best_observed_result_bo))\n",
        "    print(\"Current best RS hypervolume: \" + str(best_observed_result_rs))\n",
        "    print(f\"Number of iterations done: {(j+1)}\")\n",
        "    print(f\"Number of experiment: {(i+1)}\")"
      ],
      "metadata": {
        "id": "eQftVjQmoI65"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We give the recommendation as the best observed result. "
      ],
      "metadata": {
        "id": "9F3ZpfJ9sI0W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "best_observed_result = np.max(experiment_results)\n",
        "index_set = np.where(experiment_results==best_observed_result)\n",
        "print(\"The best observed result is: \" + str(best_observed_result))\n",
        "print(\"The best observed result belong to the : \" + str(index_set[0][0]) + \" method. Its value is \" + str(experiment_configurations[index_set][0]))"
      ],
      "metadata": {
        "id": "_GiH1UjZsN6u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "And now we plot the results to compare both methods."
      ],
      "metadata": {
        "id": "YmGKOYwGsOEE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import plotly.graph_objects as go\n",
        "\n",
        "x = np.linspace(1, n_iterations, n_iterations).astype(int)\n",
        "mean_bo = np.mean(experiment_results[0,:,:], axis=0)\n",
        "mean_rs = np.mean(experiment_results[1,:,:], axis=0)\n",
        "std_bo = np.std(experiment_results[0,:,:], axis=0)\n",
        "std_rs = np.std(experiment_results[1,:,:], axis=0)\n",
        "bo_ub_results = go.Scatter(x=x, y=mean_bo + 0.5*std_bo, mode='lines', name=\"\", line_color=\"green\", line_width=0.1)\n",
        "bo_results = go.Scatter(x=x, y=mean_bo, mode='lines', fill='tonexty', line_color=\"green\", name=\"Bayesian Optimization\")\n",
        "bo_lb_results = go.Scatter(x=x, y=mean_bo - 0.5*std_bo, mode='lines', fill='tonexty', name=\"\", line_color=\"green\", line_width=0.1)\n",
        "\n",
        "rs_ub_results = go.Scatter(x=x, y=mean_rs + 0.5*std_rs, mode='lines', name=\"\", line_color=\"red\", line_width=0.1)\n",
        "rs_results = go.Scatter(x=x, y=mean_rs, mode='lines', fill='tonexty', line_color=\"red\", name=\"Random Search\")\n",
        "rs_lb_results = go.Scatter(x=x, y=mean_rs - 0.5*std_rs, mode='lines', fill='tonexty', name=\"\", line_color=\"red\", line_width=0.1)\n",
        "  \n",
        "fig = go.Figure()\n",
        "fig.add_trace(bo_ub_results)\n",
        "fig.add_trace(bo_results)\n",
        "fig.add_trace(bo_lb_results)\n",
        "fig.add_trace(rs_ub_results)\n",
        "fig.add_trace(rs_results)\n",
        "fig.add_trace(rs_lb_results)\n",
        "fig.update_layout(title=\"Performance comparison between BO and RS. MLP full experiment.\", xaxis_title=\"Iterations\", yaxis_title=\"Accuracy lower bound\")\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "F0Y7gfG5sQJb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}