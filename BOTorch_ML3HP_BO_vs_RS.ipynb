{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# BOTorch tutorial\n",
        "Here we illustrate how to tune two machine learning hyper-parameters using BOTorch. In this notebook we will compare BO's performance with respect to RS."
      ],
      "metadata": {
        "id": "Ut_7qUec_fPS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "First we install BOTorch"
      ],
      "metadata": {
        "id": "lUHXZaZ-EBaH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install botorch"
      ],
      "metadata": {
        "id": "DRylSzQ1EC0X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import libraries. We will just tune the alpha regularization term of a MLPClassifier, the number of neurons in the hidden layer and the momentum value on a synthetic classification problem."
      ],
      "metadata": {
        "id": "aLB1XvRk_cp0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H_k6vXoy_Y4p"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "import plotly\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "seed=1\n",
        "np.random.seed(seed)\n",
        "torch.manual_seed(seed)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Objective function: Estimation of the generalization error measured by the lower confidence bound of the accuracy loss function of a multilayer perceptron whose weights are estimated via a k-fold cross validation on a synthetic dataset of 20 variables $\\mathbf{X}$ to perform binary classification of the dummy variable $y$. We do not need to shuffle the dataset as it is synthetic, but watch out of that for real problems."
      ],
      "metadata": {
        "id": "sO5iEVhA_n8i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X, y = make_classification(n_samples=1000, random_state=1)"
      ],
      "metadata": {
        "id": "6VmkhXB4-VTY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We have a low fidelity of the real performance brought by this classifier here as I limit the number of epochs of the MLP to 150 for didactic purposes. Also, the variance of the classifier can be improved by setting a higher number of folds, but I also set it to 3 for didactic purposes. We set the synthetic problem to be common for all the experiments. We introduce the concept of fidelity, would need to be high for real experiments. Here, only an approximation of the real objective function."
      ],
      "metadata": {
        "id": "9GS_cR4tD9UH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def target_function(hyperparameter_sample, seed=1, fidelity=\"low\"):\n",
        "  #For more clarity, I declare a variable for each hyper-parameter, although it is a begginer move. \n",
        "  if fidelity == \"low\":\n",
        "    max_epochs = 150\n",
        "    folds = 3\n",
        "  else: \n",
        "    max_epochs = 500\n",
        "    folds = 10\n",
        "  alpha_regularizer = float(hyperparameter_sample[0])\n",
        "  momentum_value = float(hyperparameter_sample[1])\n",
        "  hidden_layer_size_value = int(hyperparameter_sample[2])\n",
        "  X, y = make_classification(n_samples=1000, random_state=1)\n",
        "  clf = MLPClassifier(random_state=seed, max_iter=max_epochs, alpha=alpha_regularizer, momentum=momentum_value, hidden_layer_sizes=(hidden_layer_size_value))\n",
        "  scores = cross_val_score(clf, X, y, cv=folds)\n",
        "  obj_function = scores.mean() - scores.std()\n",
        "  result = []\n",
        "  result.append(obj_function)\n",
        "  print(\"Estimation of the accuracy of the MLP on the synthetic dataset done\")\n",
        "  return result"
      ],
      "metadata": {
        "id": "pBQXY7oZ_o3S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Print the accuracy function of the alpha hyper-parameter, that we want to maximize. Here we set the resolution to 100 for didactic purposes. As the 3-fold CV estimates three models to estimate the value of the accuracy parameter that represents the generalization error, we are really training 300 models here. So this may be computationally costly. The other hyper-parameters are set by default, to see the whole function over the input space we would need a 3D visualization."
      ],
      "metadata": {
        "id": "F6FwE1eYABoy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import plotly.graph_objects as go\n",
        "\n",
        "lower_bound = 0.000001\n",
        "upper_bound = 0.1\n",
        "resolution = 10\n",
        "#resolution = 100\n",
        "x = np.linspace(lower_bound, upper_bound, resolution)\n",
        "x_new = x.reshape((resolution,-1))\n",
        "z = np.array([target_function(np.array([alpha, 0.9, 10])) for alpha in x]).reshape((resolution))\n",
        "\n",
        "data = go.Scatter(x=x, y=z, line_color=\"#FE73FF\")\n",
        "\n",
        "fig = go.Figure(data=data)\n",
        "fig.update_layout(title=\"Accuracy estimated by 3-fold-CV\", xaxis_title=\"Alpha regularizer value\", yaxis_title=\"Accuracy\")\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "ZlqngMKbAEA6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We now set the bounds for the optimization. First one is the range of the alpha hyper-parameter, then the range for the momentum hyper-parameter and, lastly, the range of the number of neurons of the MLP. Our input space is hence a cube contained in $\\mathbb{R}^3$."
      ],
      "metadata": {
        "id": "Q5pPnMeXAJXt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bounds = np.array([[0.000001, 0.8, 10],[0.1, 0.999, 300]])"
      ],
      "metadata": {
        "id": "W_qml9fAAMFf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Generate some data. Example of 1000 random points from the input space, normalized into the range. We can see that their values lie in the range."
      ],
      "metadata": {
        "id": "H3VlN1QSBIJs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_x = torch.rand(1000, len(bounds[0])) * (bounds[1] - bounds[0]) + bounds[0]\n",
        "print(torch.min(train_x, axis=0))\n",
        "print(torch.max(train_x, axis=0))"
      ],
      "metadata": {
        "id": "-FzuqL7TBJSy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can observe a random sample of the hyper-parameter uniform distribution. "
      ],
      "metadata": {
        "id": "X3kPMk5lByR3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_x[0]"
      ],
      "metadata": {
        "id": "4JmhWlAlBvKj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Then we compute the latent function $f(\\mathbf{x})$. The true evaluation would be contaminated. $y = f(\\mathbf{x}) + \\epsilon \\quad s.t. \\quad \\epsilon \\approx N(0, \\sigma) \\quad f: \\mathbb{R}^3 \\to \\mathbb{R}$"
      ],
      "metadata": {
        "id": "FSg7ptujBZkG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "exact_obj = target_function(train_x[0], seed=seed)\n",
        "exact_obj"
      ],
      "metadata": {
        "id": "cI-7IyqPBOru"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We wrap all of the previous code into a function to be used freely"
      ],
      "metadata": {
        "id": "ibI-21seCe6U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_initial_data(n=10):\n",
        "  train_x = torch.rand(n, len(bounds[0])) * (bounds[1] - bounds[0]) + bounds[0]\n",
        "  exact_obj = torch.tensor([target_function(sample) for sample in train_x])\n",
        "  best_observed_value = exact_obj.max().item()\n",
        "  return train_x, exact_obj, best_observed_value"
      ],
      "metadata": {
        "id": "QX6Y4KY4ChtU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generate_initial_data(3)"
      ],
      "metadata": {
        "id": "joClmvvSCz5C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let us now invoke this function to start the BO iteration."
      ],
      "metadata": {
        "id": "q8merVh3DEZM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "init_x, init_y, best_init_y = generate_initial_data(3)"
      ],
      "metadata": {
        "id": "mqXQD_GxDGxS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We now declare a function that give us a suggestion with respect to the GP fitted to previous points."
      ],
      "metadata": {
        "id": "NNgRjAMYEc75"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from botorch.acquisition.analytic import UpperConfidenceBound\n",
        "from botorch.optim import optimize_acqf\n",
        "from botorch.utils.transforms import standardize, normalize, unnormalize\n",
        "from botorch.models import SingleTaskGP\n",
        "from gpytorch.mlls.exact_marginal_log_likelihood import ExactMarginalLogLikelihood\n",
        "from botorch import fit_gpytorch_model\n",
        "\n",
        "def get_next_points(init_x, init_y, best_init_y, normalized_bounds, n_points=1):\n",
        "  single_model = SingleTaskGP(init_x, init_y)\n",
        "  mll = ExactMarginalLogLikelihood(single_model.likelihood, single_model)\n",
        "  fit_gpytorch_model(mll)\n",
        "\n",
        "  UCB = UpperConfidenceBound(model=single_model, beta=0.2, maximize=True)\n",
        "  \n",
        "  candidates, _ = optimize_acqf(acq_function=UCB, bounds=normalized_bounds, q=n_points, num_restarts=200, raw_samples=512, options={\"batch_limit\": 5, \"maxiter\": 200})\n",
        "  best_candidate = unnormalize(init_x[((init_y == best_init_y).nonzero(as_tuple=True)[0])][0][0], bounds=normalized_bounds)\n",
        "  best_candidate_normalized = init_x[((init_y == best_init_y).nonzero(as_tuple=True)[0])][0][0]\n",
        "\n",
        "  return candidates"
      ],
      "metadata": {
        "id": "XS4zdkHyjGWX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we will compare the performance of RS vs BO. We just do, for didactic purposes, 3 iterations with different random seed of each method. In order to do it better, we will need 30 iterations of both methods and then perform a t-test of 2 means statistical hypotheses test. We save the performance in each iteration of the methods. Both methods have an initial random observation."
      ],
      "metadata": {
        "id": "M-7Zz2G1oJbd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n_experiments = 3\n",
        "n_iterations= 20\n",
        "n_methods = 2\n",
        "\n",
        "#We store the results in this tensor, we just have two methods to compare.\n",
        "experiment_results = np.zeros((n_methods, n_experiments, n_iterations))\n",
        "experiment_configurations = np.zeros((n_methods, n_experiments, n_iterations, len(bounds[0])))\n",
        "normalized_bounds = torch.tensor([np.zeros(len(bounds[0])), np.ones(len(bounds[0]))])\n",
        "bounds = np.array([[0.000001, 0.8, 10.0],[0.1, 0.999, 300.0]])\n",
        "\n",
        "for i in range(n_experiments):\n",
        "  np.random.seed(i)\n",
        "  torch.manual_seed(i)\n",
        "\n",
        "  init_x, init_y, best_init_y = generate_initial_data(1)\n",
        "  init_x_normalized = normalize(init_x, bounds=bounds) #Cool! Works for any dimension.\n",
        "  init_y_standardized = standardize(init_y)\n",
        "  best_init_y_standardized = init_y_standardized.max().item()\n",
        "\n",
        "  candidates=[]\n",
        "  results=[]\n",
        "  \n",
        "  best_observed_result_bo = 0\n",
        "  random_sample_hyperparameters = torch.rand(1, len(bounds[0])) * (bounds[1] - bounds[0]) + bounds[0]\n",
        "  best_observed_result_rs = target_function(random_sample_hyperparameters[0])[0]\n",
        "  best_observed_candidate_bo = 0\n",
        "  best_observed_candidate_rs = random_sample_hyperparameters\n",
        "  for j in range(n_iterations):\n",
        "\n",
        "    #BO Code.\n",
        "    normalized_new_candidates = get_next_points(init_x_normalized, init_y_standardized, best_init_y_standardized, normalized_bounds)\n",
        "    new_candidates = unnormalize(normalized_new_candidates, bounds=bounds)\n",
        "    new_results = torch.tensor([target_function(new_candidates[0])])\n",
        "\n",
        "    print(f\"New candidates are: {new_candidates}\")\n",
        "    init_x = torch.cat([init_x, new_candidates])\n",
        "    init_y = torch.cat([init_y, new_results])\n",
        "    init_x_normalized = normalize(init_x, bounds=bounds)\n",
        "    init_y_standardized = standardize(init_y)\n",
        "\n",
        "    best_init_y = init_y.max().item()\n",
        "    best_init_y_standardized = init_y_standardized.max().item()\n",
        "    print(f\"Best point performs this way: {best_init_y}\")\n",
        "    candidates.append(float(normalized_new_candidates[0][0]))\n",
        "    results.append(float(standardize(new_results[0][0])))\n",
        "\n",
        "    if best_observed_result_bo < new_results[0][0]:\n",
        "      best_observed_result_bo = new_results[0][0]\n",
        "      best_observed_candidate_bo = new_candidates[0][0]\n",
        "\n",
        "    experiment_configurations[0,i,j,:] = best_observed_candidate_bo\n",
        "    experiment_results[0,i,j] = best_observed_result_bo\n",
        "\n",
        "    ##RS Code.\n",
        "    #I sample the hyperparameter value for random search here.\n",
        "    random_sample_hyperparameters = torch.rand(1, len(bounds[0])) * (bounds[1] - bounds[0]) + bounds[0]\n",
        "    rs_obj_fun_result = target_function(random_sample_hyperparameters[0])[0]\n",
        "    \n",
        "    if best_observed_result_rs < rs_obj_fun_result:\n",
        "      best_observed_result_rs = rs_obj_fun_result\n",
        "      best_observed_candidate_rs = random_sample_hyperparameters\n",
        "    experiment_configurations[1,i,j,:] = best_observed_candidate_rs\n",
        "    experiment_results[1,i,j] = best_observed_result_rs\n",
        "    print(f\"Number of iterations done: {(j+1)}\")\n",
        "    print(f\"Number of experiment: {(i+1)}\")"
      ],
      "metadata": {
        "id": "eQftVjQmoI65"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We give the recommendation as the best observed result. "
      ],
      "metadata": {
        "id": "9F3ZpfJ9sI0W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "best_observed_result = np.max(experiment_results)\n",
        "index_set = np.where(experiment_results==best_observed_result)\n",
        "print(\"The best observed result is: \" + str(best_observed_result))\n",
        "print(\"The best observed result belong to the : \" + str(index_set[0][0]) + \" method. Its value is \" + str(experiment_configurations[index_set][0]))"
      ],
      "metadata": {
        "id": "_GiH1UjZsN6u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "And now we plot the results to compare both methods."
      ],
      "metadata": {
        "id": "YmGKOYwGsOEE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import plotly.graph_objects as go\n",
        "\n",
        "x = np.linspace(1, n_iterations, n_iterations).astype(int)\n",
        "mean_bo = np.mean(experiment_results[0,:,:], axis=0)\n",
        "mean_rs = np.mean(experiment_results[1,:,:], axis=0)\n",
        "std_bo = np.std(experiment_results[0,:,:], axis=0)\n",
        "std_rs = np.std(experiment_results[1,:,:], axis=0)\n",
        "bo_ub_results = go.Scatter(x=x, y=mean_bo + 0.5*std_bo, mode='lines', name=\"\", line_color=\"green\", line_width=0.1)\n",
        "bo_results = go.Scatter(x=x, y=mean_bo, mode='lines', fill='tonexty', line_color=\"green\", name=\"Bayesian Optimization\")\n",
        "bo_lb_results = go.Scatter(x=x, y=mean_bo - 0.5*std_bo, mode='lines', fill='tonexty', name=\"\", line_color=\"green\", line_width=0.1)\n",
        "\n",
        "rs_ub_results = go.Scatter(x=x, y=mean_rs + 0.5*std_rs, mode='lines', name=\"\", line_color=\"red\", line_width=0.1)\n",
        "rs_results = go.Scatter(x=x, y=mean_rs, mode='lines', fill='tonexty', line_color=\"red\", name=\"Random Search\")\n",
        "rs_lb_results = go.Scatter(x=x, y=mean_rs - 0.5*std_rs, mode='lines', fill='tonexty', name=\"\", line_color=\"red\", line_width=0.1)\n",
        "  \n",
        "fig = go.Figure()\n",
        "fig.add_trace(bo_ub_results)\n",
        "fig.add_trace(bo_results)\n",
        "fig.add_trace(bo_lb_results)\n",
        "fig.add_trace(rs_ub_results)\n",
        "fig.add_trace(rs_results)\n",
        "fig.add_trace(rs_lb_results)\n",
        "fig.update_layout(title=\"Performance comparison between BO and RS. MLP full experiment.\", xaxis_title=\"Iterations\", yaxis_title=\"Accuracy lower bound\")\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "F0Y7gfG5sQJb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}